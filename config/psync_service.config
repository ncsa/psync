# this is a source'd bash file
# this file will get sourced by psync_service, which will already have sourced
# the main bashrc, so no need to attempt to source bashrc again here

BIN=$PSYNCVENVDIR/bin
HOST=$( hostname )
PRG="$( basename "$0" )"
VAR="$PSYNCVARDIR/$PRG/$HOST"

# Names of nodes to start
#   most will only start one node:
CELERYD_NODES="psync_worker1"
#   but you can also start multiple and configure settings
#   for each in CELERYD_OPTS (see `celery multi --help` for examples).
#CELERYD_NODES="worker1 worker2 worker3"

# Absolute or relative path to the 'celery' command:
CELERY_BIN="$BIN/celery"

# App instance to use
# comment out this line if you don't use an app
CELERY_APP="psync"
# or fully qualified:
#CELERY_APP="proj.tasks:app"

# Where to chdir at start.
CELERYD_CHDIR="$PSYNCBASEDIR"

# Extra command-line arguments to the worker
# 244800 = 68 hours (3 days - 4 hours)
# 259200 = 72 hours (3 days)
CELERYD_OPTS="--soft-time-limit=$PSYNCSOFTTIMEOUT --time-limit=$PSYNCHARDTIMEOUT --concurrency=$PSYNCCONCURRENCY -O fair"

# %N will be replaced with the first part of the nodename.
CELERYD_LOG_FILE="$VAR/%N.log"
CELERYD_PID_FILE="$VAR/%N.pid"

# Workers should run as an unprivileged user.
#   You need to create this user manually (or you can choose
#   a user/group combination that already exists, e.g. nobody).
CELERYD_USER="root"
CELERYD_GROUP="root"

# If enabled pid and log directories will be created if missing,
# and owned by the userid/group configured.
CELERY_CREATE_DIRS=1

# Worker log level
# Can be one of DEBUG, INFO, WARNING, ERROR or CRITICAL
CELERYD_LOG_LEVEL="WARNING"

#need this for using Python Pickle as the serializer when run as root
export C_FORCE_ROOT="true"
